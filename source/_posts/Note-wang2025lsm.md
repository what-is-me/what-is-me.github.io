---
mathjax: true
title: 泛读笔记：《Rethinking The Compaction Policies in LSM-trees》
tags:
  - Reading Note
  - DataBase
  - LSM Tree
category: 泛读笔记
date: 2025-06-29 13:15:51
---
[Paper](https://dl.acm.org/doi/pdf/10.1145/3725344)

## 摘要

日志结构合并树 (LSM-trees) 被广泛应用于构建键值存储系统。它们会定期合并重叠的有序运行 (sorted runs) 以减少读取放大 (read amplification)。以往关于压缩 (compaction) 策略的研究主要集中在写入放大 (write amplification, WA) 和读取放大 (read amplification, RA) 之间的权衡。

在本文中，我们提出将 LSM-trees 中的压缩操作视为一种计算和 I/O 带宽投资，旨在提高系统未来的查询吞吐量，从而重新思考压缩策略的设计。典型的 LSM-tree 应用会处理稳定但中等的写入流，并优先为小规模有序运行的顶层刷新 (top-level flushes) 分配资源，以避免因写入停顿造成数据丢失。因此，压缩策略的目标是维护最佳数量的有序运行，以最大限度地提高平均查询吞吐量。

由于压缩和读取操作会争夺相同的 CPU 和 I/O 资源，我们必须进行联合优化，以确定压缩的适当时间和积极程度。我们引入了一个 LSM-tree 的三级模型，并提出了 EcoTune，这是一种基于动态规划的算法，可以根据工作负载特征找到最优的压缩策略。我们对 RocksDB 的评估表明，在具有范围/点查询比率的工作负载下，EcoTune 相较于分层 (leveling) 策略可将平均查询吞吐量提高 1.5 倍至 3 倍，相较于惰性分层 (lazy-leveling) 策略可提高高达 1.8 倍。

<!--more-->

## 简介

以往的工作主要关注写放大和读放大的权衡，并认为写放大会导致低性能。实际上LSM树的写入流平稳且适度（写入速度不是很高）（Meta展示实际负载峰值45MB/s，远小于NVMe SSD提供的2GB/s带宽）。并且为了防止写停顿，会优先处理顶层的数据刷新。实验表明，将剩余的CPU和IO资源分配任意比例分配给压缩和查询都不会影响写入性能。因此，**压缩策略的目标是优化查询性能**，并且由于压缩操作和读取操作需要争夺相同的剩余 CPU 和 I/O 资源，因此需要联合优化。

以往的研究通常使用压缩操作刚完成后的最坏情况来建模查询性能。实际上读放大会随着有序段（sorted run）的数量变化而改变。因此应该看**平均查询吞吐量**指标而非瞬态的读放大指标。

> 实验：经典的 Leveling 策略相比 Lazy Leveling 策略具有更小的读放大（瞬态），但是查询吞吐量低，因为 Leveling 中的压缩操作消耗了超过一半原本可用于查询的 CPU 资源。
>
> ![图1](image-20250629142732083.png)

本文研究问题：**在面对持续不断的写入（以恒定的刷写速度）时，如何在一个压缩轮次内设计压缩策略，以最大化平均查询吞吐量**。压缩的本质是通过投入计算资源和 I/O 来减少有序段的数量，从而使未来的查询可以扫描更少的有序运行。然而，这种效果是暂时的，因为新的有序段会不断生成。一次压缩在未来带来的收益，取决于它对当前查询吞吐量的提升程度以及该提升效果持续的时间。

压缩的时机在决定其效果持续时间方面至关重要。越早在下一次全局压缩之前执行压缩，其对平均查询吞吐量的提升就越大。（压缩越早，更多查询能从中受益）。因此一个理想的设计应在不同时间采用不同的压缩策略。这意味着同一物理层级中的有序段应该具有不同的大小，因为它们是在不同时间创建的。因此物理层级的概念变得模糊。

贡献：

1. 提出将 LSM-tree 中的压缩视为一种资源投资，其目标是提升系统的平均查询吞吐量；
2. 在概念上引入了一个三层模型来理解 LSM-tree，并设计了一种动态规划算法 EcoTune，用于为不同的 LSM-tree 实例寻找最优的压缩策略；
3. 将 EcoTune 压缩策略集成到 RocksDB 中。实验结果表明，EcoTune 在不同负载下都显著优于其他方案，有效提升了 RocksDB 的平均查询性能。

## 背景

### 压缩策略

- Leveling：
  - 一层只有一个排序段，每层的大小限制是上一层的$T$倍
  - 当一层到达大小限制，该层会和下一层合并
  - 合并时会有两层数据量总和的写入，写放大较大
- Tiering：
  - 一层中可以有多个排序段，数量限制为$T-1$
  - 当一层到达数量限制，该层会合并并放到下一层
  - 读取时需要在更多排序段查找，读放大较大

![不同压缩策略](image-20250706133506201.png)

### 更多LSM树结构探讨

**Dostoevsky(Lazy Leveling)**：最下面几层是Leveling，最上面几层是Tiering

**LSM‑bush**：每层的排序段数量限制可以不同（文中$r_i=T^{X^{L−i−1}}$）

![LSM-Bush](image-20250706143414264.png)

**MOOSE**：每层的大小比例、排序段数量限制等都可以配置；通过数学建模来确定最佳配置

**RUSKEY**：学习模型

**Endure**：应对不确定的工作负载，找到一个在运行前就确定的、对各种工作负载都“稳健”的配置

## Compaction设计

### 对写入性能的影响

- 现代SSD有更高写入带宽，刷新和压缩可以轻松并行化
- 实际工作负载中写入的吞吐量一般不高
- 刷新应该具有最高优先级
  - **应始终为刷新预留足够的带宽和CPU资源，其余资源用于压缩和查询**
  - 一旦避免了刷新阻塞，就可以自由设计压缩策略，以提升查询性能，而无需担心写入性能

> 1L, 2L, 3L表示最后1,2,3层使用Leveling策略。
>
> 在两块现代SSD上，写入的平均和尾部延迟都不受压缩策略或CPU数量的影响
>
> <table><tr><td>Type</td><td colspan="3">Optane SSD</td><td colspan="3">NVMe SSD</td></tr><tr><td>Latency</td><td colspan="3">Average / 99th (μs)</td><td colspan="3">Average / 99th (μs)</td></tr><tr><td>#Cores</td><td>4</td><td>8</td><td>16</td><td>4</td><td>8</td><td>16</td></tr><tr><td>1L</td><td>2.8/4.1</td><td>2.8/4.2</td><td>2.9/4.4</td><td>3.3/4.3</td><td>3.4/4.3</td><td>3.4/4.5</td></tr><tr><td>2L</td><td>2.8/4.2</td><td>2.8/3.9</td><td>2.9/4.3</td><td>3.4/4.2</td><td>3.4/4.5</td><td>3.5/4.8</td></tr><tr><td>3L</td><td>2.9/4.3</td><td>2.8/4.3</td><td>2.9/4.3</td><td>3.4/4.1</td><td>3.5/4.4</td><td>3.5/4.4</td></tr></table>

### 对查询性能的影响
